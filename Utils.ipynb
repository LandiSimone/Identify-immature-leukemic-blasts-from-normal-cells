{"cells":[{"cell_type":"markdown","metadata":{"id":"IeWZefXiwBQ-"},"source":["# Utilities and Constants"]},{"cell_type":"markdown","metadata":{"id":"sRJsm-3swWZQ"},"source":["# Import"]},{"cell_type":"code","execution_count":100,"metadata":{"executionInfo":{"elapsed":415,"status":"ok","timestamp":1697273618716,"user":{"displayName":"Simone Landi","userId":"18127737155097032167"},"user_tz":-120},"id":"TU4GMYr7vzbj"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","import pandas as pd\n","from keras import layers\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import shutil\n","from tensorflow.keras import optimizers\n","import random as rn\n","import os\n","from sklearn import metrics\n","from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix"]},{"cell_type":"markdown","metadata":{"id":"39M3SzH6wfPY"},"source":["# Path Costants and Classes\n"]},{"cell_type":"code","execution_count":101,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1697273619131,"user":{"displayName":"Simone Landi","userId":"18127737155097032167"},"user_tz":-120},"id":"4yWpNFa0whnN"},"outputs":[],"source":["DRIVE_DIR = \"/content/drive/MyDrive/Colab Notebooks/B-CellLymphoblastsClassification\"\n","DATA_DIR = \"/content/drive/MyDrive/Colab Notebooks/B-CellLymphoblastsClassification/dataset/C-NMC_training_data\"\n","PREPROCESSED_DIR = \"/content/drive/MyDrive/Colab Notebooks/B-CellLymphoblastsClassification/dataset-cleaned\"\n","SETS_DIR = \"/content/drive/MyDrive/Colab Notebooks/B-CellLymphoblastsClassification/dataset-splits\"\n","MODELS_PATH = \"/content/drive/MyDrive/Colab Notebooks/B-CellLymphoblastsClassification/Models\"\n","\n","SEED = 123\n","\n","CLASSES = ['all', 'hem']"]},{"cell_type":"code","execution_count":102,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1697273619131,"user":{"displayName":"Simone Landi","userId":"18127737155097032167"},"user_tz":-120},"id":"Y0DHvnoZyra5"},"outputs":[],"source":["IMAGE_WIDTH = 224\n","IMAGE_HEIGHT = 224\n","IMAGE_SIZE = (IMAGE_HEIGHT, IMAGE_WIDTH)\n","BATCH_SIZE = 64"]},{"cell_type":"markdown","metadata":{"id":"vDCbz4dwyuBB"},"source":["# Set Seed\n"]},{"cell_type":"code","execution_count":103,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1697273619131,"user":{"displayName":"Simone Landi","userId":"18127737155097032167"},"user_tz":-120},"id":"TYyqSR-VyugC"},"outputs":[],"source":["np.random.seed(SEED)\n","rn.seed(SEED)\n","tf.random.set_seed(SEED)"]},{"cell_type":"markdown","metadata":{"id":"OZzFyZzvywbt"},"source":["# Object Handling Utilities"]},{"cell_type":"code","execution_count":104,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1697273619131,"user":{"displayName":"Simone Landi","userId":"18127737155097032167"},"user_tz":-120},"id":"oZrxbyuSyyTx"},"outputs":[],"source":["#provides functions to store and load objects from files\n","import pickle\n","\n","def saveObject(obj, path):\n","    \"\"\"\"Save an object using the pickle library on a file\n","\n","    :param obj: undefined. Object to save\n","    :param fileName: str. Name of the file of the object to save\n","    \"\"\"\n","    print(\"Saving \" + path + '.pkl')\n","    with open(path + \".pkl\", 'wb') as fid:\n","        pickle.dump(obj, fid)\n","\n","def loadObject(path):\n","    \"\"\"\"Load an object from a file\n","\n","    :param fileName: str. Name of the file of the object to load\n","    :return: obj: undefined. Object loaded\n","    \"\"\"\n","    try:\n","        with open(path + '.pkl', 'rb') as fid:\n","            obj = pickle.load(fid)\n","            return obj\n","    except IOError:\n","        return None"]},{"cell_type":"markdown","metadata":{"id":"SZp1UvM-y-mx"},"source":["# Training Utility\n"]},{"cell_type":"code","execution_count":105,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1697273619132,"user":{"displayName":"Simone Landi","userId":"18127737155097032167"},"user_tz":-120},"id":"Fy_t919dy_FP"},"outputs":[],"source":["def load_data_splits (img_size, batch_size, shuffle_on_val=True):\n","  train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","    PREPROCESSED_DIR + '/training_set',\n","    labels='inferred', #the label of the dataset is obtained by the name of the directory\n","    seed=SEED,\n","    shuffle=True,\n","    image_size=img_size,\n","    batch_size=batch_size,\n","  )\n","  val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","    PREPROCESSED_DIR + '/validation_set',\n","    labels='inferred', #the label of the dataset is obtained by the name of the directory\n","    seed=SEED,\n","    shuffle=shuffle_on_val,\n","    image_size=img_size,\n","    batch_size=batch_size,\n","  )\n","  test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","    PREPROCESSED_DIR + '/test_set',\n","    labels='inferred', #the label of the dataset is obtained by the name of the directory\n","    seed=SEED,\n","    shuffle=False,\n","    image_size=img_size,\n","    batch_size=batch_size,\n","  )\n","  return train_ds, val_ds, test_ds\n","\n","def split_dataset(dataset, dataset_size, train_percentage=0.6, val_percentage=0.2, test_percentage=0.2, shuffle=True):\n","  \"\"\"\n","    split_dataset splits the dataset into training, validation and test sets.\n","\n","    :param dataset: a list representing the whole dataset\n","    :param dataset_size: number of elements in the dataset\n","    :param train_percentage: the percentage of the dataset that will be used for training\n","    :param val_percentage: the percentage of the dataset that will be used for validation\n","    :param test_percentage: the percentage of the dataset that will be used for testing\n","    :param shuffle: if True the elements of the dataset will be randomly shuffled\n","    :return: three lists representing the training, validation and test sets\n","  \"\"\"\n","  if train_percentage + val_percentage + test_percentage != 1:\n","    print('Total of percentages must be 1')\n","    return None, None, None\n","\n","  if shuffle:\n","    random.shuffle(dataset)\n","\n","  train_size = int(train_percentage * dataset_size)\n","  val_size = int(val_percentage * dataset_size)\n","\n","  train_set = dataset[0:train_size]\n","  val_set = dataset[train_size:train_size+val_size]\n","  test_set = dataset[train_size+val_size:dataset_size]\n","\n","  return train_set, val_set, test_set\n","\n","\n","def compile_model(model, metrics='accuracy', loss='binary_crossentropy', optimizer='adam', learning_rate = 0.0005):\n","  '''\n","    compile_model is used to compile the current model\n","    :param model: model to compile\n","    :param optimizer: optimizer to be used\n","    :param learning_rate: learning rate parameter for the optimizer\n","  '''\n","  if optimizer == 'adam':\n","    optimizer=optimizers.Adam(learning_rate=learning_rate)\n","  elif optimizer == 'rmsprop':\n","    optimizer = optimizers.RMSprop(learning_rate=learning_rate)\n","  else:\n","    return\n","\n","  model.compile(loss=loss,\n","    optimizer=optimizer,\n","    metrics=[metrics])\n","\n","  return model\n","\n","def run_model (model, model_name, train_ds, val_ds, epochs=50, patience=5, monitor='val_loss'):\n","  '''\n","  run_model is used to run the current mode\n","  :param model: model to run\n","  :param model_name: name given to save the model\n","  :param epochs: how many epochs to do\n","  :param patience: patience value for Early Stopping\n","  :param monitor: what to monitor for Early Stopping and Model Checkpoint\n","  '''\n","  # local save path for the models\n","  local_path = \"/content/model/\" + model_name + '.h5'\n","  drive_path = MODELS_PATH + '/' + model_name\n","\n","  # Create local directory\n","  #if not os.path.exists(local_path):\n","  #  os.makedirs(local_path)\n","\n","  # Create derive directory\n","  #if not os.path.exists(drive_path):\n","  #  os.makedirs(drive_path)\n","\n","  #deletes old model\n","  try:\n","    shutil.rmtree(drive_path)\n","  except:\n","    pass\n","  os.mkdir(drive_path)\n","  callbacks_list = [\n","                  keras.callbacks.EarlyStopping(monitor=monitor, patience=patience), #we implement EarlyStopping to prevent overfitting\n","                  keras.callbacks.ModelCheckpoint(\n","                      filepath = local_path,\n","                      monitor=monitor,\n","                      verbose=1,\n","                      save_best_only=True)\n","                  ]\n","  history = model.fit(train_ds,\n","                    epochs=epochs,\n","                    validation_data=val_ds,\n","                    callbacks=callbacks_list)\n","\n","  history_to_save = {\n","    'loss': history.history['loss'],\n","    'val_loss': history.history['val_loss'],\n","    'accuracy': history.history['accuracy'],\n","    'val_accuracy': history.history['val_accuracy']\n","  }\n","\n","  # save on Drive only the best model\n","  shutil.copy(local_path, drive_path + '/' + model_name + '.h5')\n","  # save on Drive also the history\n","  saveObject(history_to_save, drive_path + '/history')\n","\n","  #try:\n","  #  saveObject(history, drive_path + '/history')\n","  #except Exception as e:\n","  #  print(f\"An error occurred while saving the object: {str(e)}\")\n","\n","  return tf.keras.models.load_model(local_path), history\n"]},{"cell_type":"markdown","metadata":{"id":"IOk4241NzvVc"},"source":["we provide keras layers that performs data augmentation in order to fight overfitting"]},{"cell_type":"code","execution_count":106,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1697273619132,"user":{"displayName":"Simone Landi","userId":"18127737155097032167"},"user_tz":-120},"id":"BDf2msTUzyTS"},"outputs":[],"source":["data_augmentation_layers = keras.Sequential(\n","  [\n","      layers.RandomFlip(\"horizontal\"), # Applies horizontal flipping to a random 50% of the images\n","      layers.RandomFlip(\"vertical\"), # Applies vertical flipping to a random 50% of the images\n","      layers.RandomContrast(0.20), # Randomly adjust the contrast of an image or images by a random factor in the range[–20%, +20%]\n","  ]\n",")"]},{"cell_type":"markdown","metadata":{"id":"f1s1CrL60AEi"},"source":["# Evaluation Utilities\n"]},{"cell_type":"code","execution_count":107,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1697273619132,"user":{"displayName":"Simone Landi","userId":"18127737155097032167"},"user_tz":-120},"id":"CRnchhE5z-HQ"},"outputs":[],"source":["def plot_accuracy_and_loss_history(history):\n","  acc = history.history['accuracy']\n","  val_acc = history.history['val_accuracy']\n","  loss = history.history['loss']\n","  val_loss = history.history['val_loss']\n","\n","  epochs = range(len(acc))\n","\n","  plt.plot(epochs, acc, 'bo', label='Training accuracy')\n","  plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n","  plt.title('Training and validation accuracy')\n","  plt.legend()\n","\n","  plt.figure()\n","\n","  plt.plot(epochs, loss, 'bo', label='Training loss')\n","  plt.plot(epochs, val_loss, 'b', label='Validation loss')\n","  plt.title('Training and validation loss')\n","  plt.legend()\n","\n","  plt.show()\n","\n","def evaluate_model(model, test_ds):\n","  y_score = model.predict(test_ds)\n","  y_pred = np.rint(y_score)  # round value to 0 or 1\n","  y_true = tf.concat([labels_batch for data_batch, labels_batch in test_ds], axis=0)\n","\n","  # 0 --> all and 1 --> hem\n","  y_true = np.where(y_true == 0, \"all\", \"hem\")\n","  y_pred = np.where(y_pred == 0, \"all\", \"hem\")\n","\n","  print(\"Classification report:\")\n","  print(metrics.classification_report(y_true, y_pred, target_names=[\"all\", \"hem\"], digits=4))\n","\n","def plot_confusionmatrix(model, test_ds):\n","    y_score = model.predict(test_ds)\n","    y_pred = np.rint(y_score)  # round value to 0 or 1\n","    y_true = tf.concat([labels_batch for data_batch, labels_batch in test_ds], axis=0)\n","\n","    # 0 --> all and 1 --> hem\n","    y_true = np.where(y_true == 0, \"all\", \"hem\")\n","    y_pred = np.where(y_pred == 0, \"all\", \"hem\")\n","\n","    # produce and show confusion matrix\n","    cm = confusion_matrix(y_true, y_pred, labels=[\"all\", \"hem\"])\n","    fig, ax = plt.subplots(figsize=(10, 10))\n","    ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"all\", \"hem\"]).plot(cmap=\"viridis\", ax=ax)\n","\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"k1rm9VQwSCJs","executionInfo":{"status":"ok","timestamp":1697273621994,"user_tz":-120,"elapsed":2868,"user":{"displayName":"Simone Landi","userId":"18127737155097032167"}},"outputId":"ac2fd58a-0a57-48c2-d78c-253d40b72ce7","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":108,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}